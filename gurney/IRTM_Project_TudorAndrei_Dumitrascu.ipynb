{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IRTM Project 2\n",
    "Dumitrascu Tudor Andrei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from statistics import mean\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", exclude=['ner', 'lemmatizer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Lyrics-Genre-Train.csv\").drop(['Song', 'Song year', 'Artist', 'Track_id'], axis=1)\n",
    "data_test = pd.read_csv(\"Lyrics-Genre-Test-GroundTruth.csv\").drop(['Song', 'Song year', 'Artist', 'Track_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pos(x) -> str:\n",
    "    doc = nlp(x)\n",
    "    results = []\n",
    "    for i, token in enumerate(doc):\n",
    "        results.append(token.pos_)\n",
    "    \n",
    "    return \" \".join(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['POS'] = data['Lyrics'].apply(generate_pos)\n",
    "data_test['POS'] = data_test['Lyrics'].apply(generate_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(model, X_train, y_train, X_test, y_test, encoder):\n",
    "    print(str(model))\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Train\")\n",
    "    y_hat = model.predict(X_train)\n",
    "    print(f1_score(y_train, y_hat, average='weighted'))\n",
    "    print(\"Test\")\n",
    "    y_hat = model.predict(X_test)\n",
    "    print(f1_score(y_test, y_hat, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verse Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_count(x, pos):\n",
    "    return sum([y == pos for y in x.split() ])\n",
    "    \n",
    "# count the part of speech tags in the whole song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJ',\n",
       " 'ADP',\n",
       " 'ADV',\n",
       " 'AUX',\n",
       " 'CCONJ',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'PRON',\n",
       " 'PROPN',\n",
       " 'PUNCT',\n",
       " 'SPACE',\n",
       " 'VERB'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "poeses = set(data.loc[0,'POS'].split())\n",
    "poeses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.52it/s]\n"
     ]
    }
   ],
   "source": [
    "for pos in tqdm(poeses):\n",
    "    data[ pos + \"_count\"] = data['POS'].apply(lambda x: pos_count(x, pos))\n",
    "    data_test[ pos + \"_count\"] = data_test['POS'].apply(lambda x: pos_count(x, pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of verses\n",
    "data['newln_count'] = data['Lyrics'].apply(lambda x: x.count(\"\\n\"))\n",
    "data_test['newln_count'] = data_test['Lyrics'].apply(lambda x: x.count(\"\\n\"))\n",
    "# Count the avg verse length\n",
    "data['mean_verse_len'] = data['Lyrics'].apply(lambda x: mean([len(y) for y in x.split(\"\\n\")]))\n",
    "data_test['mean_verse_len'] = data_test['Lyrics'].apply(lambda x: mean([len(y) for y in x.split(\"\\n\")]))\n",
    "# count the avg no. of words per verse\n",
    "data['mean_word_count_per_verse']  = data['Lyrics'].apply(lambda x: mean([len(y.split()) for y in x.split(\"\\n\")]))\n",
    "data_test['mean_word_count_per_verse']  = data_test['Lyrics'].apply(lambda x: mean([len(y.split()) for y in x.split(\"\\n\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.drop(['Genre', 'Lyrics', 'POS'], axis=1)\n",
    "X_test = data_test.drop(['Genre', 'Lyrics', 'POS'], axis=1)\n",
    "enc = LabelEncoder()\n",
    "y_train = enc.fit_transform(data['Genre'])\n",
    "y_test = enc.transform(data_test['Genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(class_weight='balanced')\n",
      "Train\n",
      "0.2917416059978742\n",
      "Test\n",
      "0.277862611528458\n"
     ]
    }
   ],
   "source": [
    "train_eval(SVC(class_weight='balanced'), X_train, y_train, X_test, y_test, enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=10)\n",
      "Train\n",
      "0.3493602597226395\n",
      "Test\n",
      "0.23033025647020453\n"
     ]
    }
   ],
   "source": [
    "train_eval(DecisionTreeClassifier(class_weight=\"balanced\", criterion='entropy', max_depth=10), X_train, y_train, X_test, y_test, enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(n_jobs=-1)\n",
      "Train\n",
      "0.9998919615100562\n",
      "Test\n",
      "0.29142742830782753\n"
     ]
    }
   ],
   "source": [
    "train_eval(RandomForestClassifier(n_jobs=-1), X_train, y_train, X_test, y_test, enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf =  TfidfVectorizer(ngram_range=(1,3), max_features=2000, max_df=0.8, min_df=0.2)\n",
    "X_train = tfidf.fit_transform(data['Lyrics'])\n",
    "X_test = tfidf.transform(data_test['Lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n",
    "y_train = enc.fit_transform(data['Genre'])\n",
    "y_test = enc.transform(data_test['Genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(class_weight='balanced')\n",
      "Train\n",
      "0.5939188926029967\n",
      "Test\n",
      "0.30550260205341334\n"
     ]
    }
   ],
   "source": [
    "train_eval(SVC(class_weight='balanced'), X_train, y_train, X_test, y_test, enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(n_jobs=-1)\n",
      "Train\n",
      "0.9992441696631217\n",
      "Test\n",
      "0.295679015623803\n"
     ]
    }
   ],
   "source": [
    "train_eval(RandomForestClassifier(n_jobs=-1), X_train, y_train, X_test, y_test, enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of speech tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf =  TfidfVectorizer(ngram_range=(1,3), max_features=300)\n",
    "X_train = tfidf.fit_transform(data['POS'])\n",
    "X_test = tfidf.transform(data_test['POS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n",
    "y_train = enc.fit_transform(data['Genre'])\n",
    "y_test = enc.transform(data_test['Genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(class_weight='balanced')\n",
      "Train\n",
      "0.4188555378773796\n",
      "Test\n",
      "0.3203567772402991\n"
     ]
    }
   ],
   "source": [
    "train_eval(SVC(class_weight='balanced'), X_train, y_train, X_test, y_test, enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(n_jobs=-1)\n",
      "Train\n",
      "0.9998379632304489\n",
      "Test\n",
      "0.30130022882875435\n"
     ]
    }
   ],
   "source": [
    "train_eval(RandomForestClassifier(n_jobs=-1), X_train, y_train, X_test, y_test, enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n",
    "y_train = enc.fit_transform(data['Genre'])\n",
    "y_test = enc.transform(data_test['Genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_len(string, max_pad=200):\n",
    "    doc = nlp.tokenizer(string)\n",
    "    results = []\n",
    "    for i, token in enumerate(doc):\n",
    "        results.append(len(token))\n",
    "    results = np.asarray(results)\n",
    "    if len(results) < max_pad:\n",
    "        results = np.pad(results, (0, max_pad - len(results)))\n",
    "    else:\n",
    "        results = results[:200]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data['Lyrics'].apply(word_len)\n",
    "X_train = np.stack(X_train.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data_test['Lyrics'].apply(word_len)\n",
    "X_test = np.stack(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max = MinMaxScaler().fit(X_train)\n",
    "X_train = min_max.transform(X_train)\n",
    "X_test = min_max.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(class_weight='balanced')\n",
      "Train\n",
      "0.5391034891259431\n",
      "Test\n",
      "0.1806859460442372\n"
     ]
    }
   ],
   "source": [
    "train_eval(SVC(class_weight='balanced'), X_train, y_train, X_test, y_test, enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(n_jobs=-1)\n",
      "Train\n",
      "0.9998919615100562\n",
      "Test\n",
      "0.16504548553924356\n"
     ]
    }
   ],
   "source": [
    "train_eval(RandomForestClassifier(n_jobs=-1), X_train, y_train, X_test, y_test, enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a77c0c35d151efa310d681fa26334dea918cb075009dff76e52c9dace28e6d0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('grn': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
